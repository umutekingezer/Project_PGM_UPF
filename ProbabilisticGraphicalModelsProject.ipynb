{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpEFtEuK3LXQ",
    "outputId": "8620032c-ff4a-464e-865f-b0b1fe1644ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '/Users/umutekingezer/opt/anaconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pgmpy\n",
    "!gdown -q --id 1b2ryMxJOhAOhiPmphsS-0sJkJKuLJ9D4\n",
    "!gdown -q --id 19xqIcNf2WvcG3Hi95d4zv7CpMaJPriMe\n",
    "!gdown -q --id 1pD496PHFtTydlXqnY4s8JpFanP46bO0E\n",
    "!gdown -q --id 1kOSQm_PBSXR1rEr7-6xStUyfja3vXH3l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemented by:\n",
    "Umut Ekin Gezer - u195839\n",
    "Pablo Brando Alvira - u172915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWEPYhPy3Jxh"
   },
   "source": [
    "# Inference in Hidden Markov Models\n",
    "\n",
    "\n",
    "In this lab session you will work with hidden Markov models (HMMs) using the [pgmpy library](http://www.pgmpy.org). By the end of the session you will be able to\n",
    "\n",
    "- Understand how to learn **hidden Markov models** from data\n",
    "- Implement the **belief propagation** to answer **filtering and prediction** queries\n",
    "- **Implement the Viterbi algorithm** for finding the most likely sequence of hidden states, given some evidence\n",
    "- Experiment with two tasks: a robot navigating on a grid, and how to improve a mispelled text\n",
    "\n",
    "This practice is inspired by https://www.cs.princeton.edu/courses/archive/fall12/cos402/assignments/programs/viterbi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDSujyY-3Jxm"
   },
   "source": [
    "## The Hidden Markov Model\n",
    "\n",
    "A HMM is defined by a Markov chain over hidden variables $h_{1:T}=h_1,h_2,...,h_T$ and it is defined by\n",
    "- a probability distribution over the initial hidden state $p(h_1)$.\n",
    "- a state transition distribution $p(h_t|h_{t-1})$.\n",
    "\n",
    "Each hidden variable $h_t$ influences a corresponding visible variable $v_t$ through the observation model $p(v_t|h_t)$. The joint distribution can be written as\n",
    "$$p(v_{1:T},h_{1:T}) = p(h_1)p(v_1|h_1)\\prod_{t=2}^T p(h_{t}|h_{t-1})p(v_t|h_t).$$\n",
    "\n",
    "Let's define a class that encodes an HMM. This class will create the HMM with a predefined length ``n_vars``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VfJ988Gu3Jxn"
   },
   "outputs": [],
   "source": [
    "from pgmpy.models import FactorGraph\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, n_vars, prior_fn, transition_fn, observation_fn, h_states, v_states, h_name='h', v_name='v'):\n",
    "        self.h = [f\"{h_name}{i}\" for i in range(n_vars)]\n",
    "        self.v = [f\"{v_name}{i}\" for i in range(n_vars)]\n",
    "        self.variables = self.h + self.v\n",
    "        self.state_names = dict([(h, h_states) for h in self.h] +\n",
    "                                [(v, v_states) for v in self.v])\n",
    "        self.f = self.create_factors(n_vars, prior_fn, transition_fn, observation_fn)\n",
    "        \n",
    "    def create_factors(self, n_vars, prior_fn, transition_fn, observation_fn):\n",
    "        \"\"\"\n",
    "        Given the amount of variables (n_vars) in the hidden markov model, it creates factors for\n",
    "        the prior of h_0, for all the transitions from h_{t-1} to h_t (for t in n_vars), and for\n",
    "        the observation function from h_t to v_t.\n",
    "        Returns a dict where keys are (tuples of) variables and values are factors.\n",
    "        E.g. {\"h_0\": DiscreteFactor,\n",
    "              (\"h_1\", \"h_2\"): DiscreteFactor,\n",
    "              (\"h_1\", \"v_1\"): DiscreteFactor,\n",
    "                           ...\n",
    "              }\n",
    "        \"\"\"\n",
    "        \n",
    "        factors = dict()      \n",
    "        for i in range(n_vars):\n",
    "            if i == 0:\n",
    "                # Prior factor\n",
    "                factors[self.h[i]] = prior_fn(self.h[i])\n",
    "            else:\n",
    "                # Transition factor\n",
    "                factors[(self.h[i-1], self.h[i])] = transition_fn(self.h[i-1], self.h[i])\n",
    "            # Observation factor\n",
    "            factors[(self.h[i], self.v[i])] = observation_fn(self.h[i], self.v[i])\n",
    "        return factors\n",
    "    \n",
    "    def to_factor_graph(self):\n",
    "        G = FactorGraph()\n",
    "        assert set(self.variables) == set(v for f in self.f.values() for v in f.variables)\n",
    "        G.add_nodes_from(self.variables)\n",
    "        G.add_factors(*self.f.values())\n",
    "        G.add_edges_from([(v, f) for f in self.f.values() for v in f.variables])\n",
    "        assert G.check_model()\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLy8NpJ83Jxq"
   },
   "source": [
    "## Basic setting\n",
    "\n",
    "Before tackling larger problems, and to be able to test our implementations, we will first consider a small version of our previous hidden Markov model of weather change over three days, where we can observe if an umbrella has been used or not. We define this factor graph next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mO6IuzSc3Jxr"
   },
   "outputs": [],
   "source": [
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.models import FactorGraph\n",
    "\n",
    "weather_states = [\"sunny\", \"cloudy\", \"rainy\"]\n",
    "umbrella_states = [True, False]\n",
    "\n",
    "def day_prior(d):\n",
    "    return DiscreteFactor(variables=[d],\n",
    "                          cardinality=[3],\n",
    "                          values=[0.3, 0.4, 0.3],\n",
    "                          state_names={d: weather_states})\n",
    "\n",
    "def day_transition(d1, d2): # P(d2|d1)\n",
    "     return DiscreteFactor(variables=[d1, d2],\n",
    "                           cardinality=[3, 3],\n",
    "                           values=[0.7, 0.25, 0.05,\n",
    "                                   0.25, 0.35, 0.4,\n",
    "                                   0.25, 0.5, 0.25],\n",
    "                           state_names={d1: weather_states,\n",
    "                                        d2: weather_states})\n",
    "\n",
    "def take_umbrella_transition(d, u): # P(u|d)\n",
    "    return DiscreteFactor(variables=[d, u],\n",
    "                          cardinality=[3, 2],\n",
    "                          values=[0.2, 0.8,\n",
    "                                  0.6, 0.4,\n",
    "                                  0.95, 0.05],\n",
    "                          state_names={d: weather_states,\n",
    "                                       u: umbrella_states})\n",
    "\n",
    "# Expand the model for 3 days\n",
    "hmm_weather_3 = HMM(n_vars=3,\n",
    "                    prior_fn=day_prior,\n",
    "                    transition_fn=day_transition,\n",
    "                    observation_fn=take_umbrella_transition,\n",
    "                    h_states=weather_states,\n",
    "                    v_states=umbrella_states,\n",
    "                    h_name=\"w\",\n",
    "                    v_name=\"u\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQxgRQD-3Jxr"
   },
   "source": [
    "## Probabilistic Queries\n",
    "\n",
    "We will implement three types of queries:\n",
    "\n",
    "1. **Filtering** : the probability of the current hidden sate given a partial sequence of observations $p(h_t|v_{1:t})$.\n",
    "2. **Prediction** : the probability of a future hidden sate given a partial sequence of observations $p(h_s|v_{1:t})$, for a $s>t$.\n",
    "3. **Evidence** : the probability of a given a full sequence of observations $p(v_{1:T})$.\n",
    "4. **MAP state** : the most likely hidden trajectory given a full sequence of observations $p(v_{1:T})$.\n",
    "\n",
    "A naive way of computing the MAP of the hidden variables can be:\n",
    "1. Clamp the corresponding visible variables $v_{1:t}$.\n",
    "2. Run BP.\n",
    "3. Compute the joint probability of the corresponding hidden variables.\n",
    "3. Get the assignment with maximum probability.\n",
    "\n",
    "\n",
    "The following code calculates the joint hidden trajectory for the weather example with $T=3$ using belief propagation. Clearly, this approach will not scale to larger models. However, we will use it to check that our code is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "b2e500ac2cc14f87971e7b8dc5f3c707",
      "e0a5c37ad2ea4541a9141631783e1533",
      "74a2644138a74c2999934b46eeb38a0d",
      "074c026fa2d4461b94ebe95d2d7d62bb",
      "99d16e6768e84c34b8042e210fab56b8",
      "87595bc31e47432081e449aeb396694a",
      "e45d82eaba7542f78e9d13108d5d12c5",
      "d609507d82d64024beebaec158078844",
      "02d5eff1da324760b336a6f7b5a5aadc",
      "527a4d7870a54e159d3e3d6d0007f10c",
      "3e88c062bf554b2f9c1cd4de74b98704"
     ]
    },
    "id": "a8ak2V8a3Jxt",
    "outputId": "982eedda-af23-42ce-8eb4-50e402b5a834"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93c8f7a42324cd1b670894ac1641fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum probability: 0.16289702507051773\n",
      "State assignment: [('w0', 'rainy'), ('w1', 'cloudy'), ('w2', 'rainy')]\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import BeliefPropagation\n",
    "import numpy as np\n",
    "\n",
    "bp = BeliefPropagation(hmm_weather_3.to_factor_graph())\n",
    "# Compute the joint probability\n",
    "joint = bp.query(variables=['w0','w1','w2'],\n",
    "                 evidence={\"u0\":True,\"u1\":True, \"u2\":True})\n",
    "# Get the index of the maximum value\n",
    "amax = np.argmax(joint.values)\n",
    "print(\"Maximum probability:\", joint.values.flatten()[amax])\n",
    "print(\"State assignment:\", sorted(joint.assignment([amax])[0])) # pgmpy's assignment function gives us the states for the given index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Kv52Egu3Jxu"
   },
   "source": [
    "## Task 1: Robot Navigation on a Grid\n",
    "\n",
    "In this problem, a robot is wandering through the following small world:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1Rq-izqt8vkkkX6FbWrhaeCuGkgggJiPF\"  alt=\"A robot on a maze\" title=\"Title text\" width=350 height=350>\n",
    "\n",
    "The robot can only occupy the colored squares.  At each time step, the robot attempts to move up, down, left or right, where the choice of direction is made at random.  If the robot attempts to move onto a black square, or to leave the confines of its world, its action has no effect and it does not move at all.  The robot can only sense the color of the square it occupies.  However, its sensors are only $90\\%$ accurate, meaning that $10\\%$ of the time, it perceives a random color rather than the true color of the currently occupied square.  The robot begins each walk in a randomly chosen colored square.\n",
    "\n",
    "In this problem, state refers to the location of the robot in the world in x:y coordinates, and output refers to a perceived color (r, g, b or y).  Thus, a typical random walk looks like this:\n",
    "\n",
    "``3:3 r``\n",
    "``3:3 r``\n",
    "``3:4 y``\n",
    "``2:4 b``\n",
    "``3:4 y``\n",
    "``3:3 r``\n",
    "``2:3 b``\n",
    "``1:3 g``\n",
    "``2:3 b``\n",
    "``2:4 r``\n",
    "``3:4 y``\n",
    "``4:4 y``\n",
    "\n",
    "Here, the robot begins in square ``3:3`` perceiving red, attempts to make an illegal move (to the right), so stays in ``3:3``, still perceiving red.  On the next step, the robot moves up to ``3:4`` perceiving yellow, then left to ``2:4`` perceiving blue (erroneously), and so on.\n",
    "\n",
    "We will provide the HMM model for this world. Then, given only sensor information (i.e., a sequence of colors), you will have to answer different queries regarding the actual path taken by the robot through its world.\n",
    "\n",
    "The data for this problem is in [robot.data](files/robot.data), a file containing $200$ training sequences (random walks) and $200$ test sequences, each sequence consisting of $200$ steps.\n",
    "\n",
    "We provide next the implementation on how to build the HMM. First, we define some functions that will become handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y3wnnbc13Jxv"
   },
   "outputs": [],
   "source": [
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "def split(s, sep):\n",
    "    \"\"\"\n",
    "    Generator that splits a sequence s into subsequences, when separator sep is found.\n",
    "    \"\"\"\n",
    "    chunk = []\n",
    "    for val in s:\n",
    "        if val == sep:\n",
    "            yield chunk\n",
    "            chunk = []\n",
    "        else:\n",
    "            chunk.append(val)\n",
    "    yield chunk\n",
    "\n",
    "def to_cpd(phi, x):\n",
    "    \"\"\"\n",
    "    Returns a TabularCPD object from a DiscreteFactor. For a given factor phi(x_0, ..., x_n)\n",
    "    and a variable x_i, it interprets the factor as a CPD P(x_i|Y), where Y is the set of all\n",
    "    variables in phi except x_i. I.e. P(x_i|x_0, ..., x_{i-1}, x_{i+1}, ..., x_n).\n",
    "    It also checks that the factor is a valid conditional probability distribution.\n",
    "    \"\"\"\n",
    "    assert x in phi.variables\n",
    "    idx = phi.variables.index(x)\n",
    "    card = list(phi.cardinality)\n",
    "    var_card = card[idx]\n",
    "    evidence_card = card[:idx] + card[idx+1:]\n",
    "    values = np.moveaxis(phi.values, idx, 0) # move variable x to dimension 0\n",
    "    return TabularCPD(variable=x,\n",
    "                      variable_card=var_card,\n",
    "                      evidence=phi.variables[:idx] + phi.variables[idx+1:],\n",
    "                      evidence_card=evidence_card,\n",
    "                      values=values.reshape(var_card, int(np.prod(evidence_card))), # int cast since np.prod([])=1.0\n",
    "                      state_names=phi.state_names)\n",
    "\n",
    "def normalize_cpd_values(variables, cardinality, values):\n",
    "    \"\"\"\n",
    "    Normalize a numpy array of CPD values. It also accounts for unreachable states (all 0s).\n",
    "    \"\"\"\n",
    "    assert len(variables) in (1,2)\n",
    "    f = DiscreteFactor(variables=variables, cardinality=cardinality, values=values)\n",
    "    # Normalize it as a CPD\n",
    "    f = to_cpd(f, variables[-1]) # Get the last variable for the CPD (e.g. [ht-1, ht] -> p(ht|ht-1))\n",
    "    f.normalize()\n",
    "    # Remove NaNs, put 0s instead\n",
    "    f.values[np.logical_not(np.isfinite(f.values))] = 0.0\n",
    "    if len(f.variables) == 2:\n",
    "        # The process f->cpd swapped the variables, let's swap them back\n",
    "        assert f.variables[1] == variables[0]\n",
    "        return np.transpose(f.values)\n",
    "    return f.values\n",
    "    \n",
    "def get_hmm_factors(trajectories, h_states, v_states):\n",
    "    \"\"\"\n",
    "    Gets the prior, transition and observation probabilities of an HMM from data.\n",
    "    \"\"\"\n",
    "    prior = np.zeros(len(h_states))\n",
    "    transition = np.zeros([len(h_states), len(h_states)])\n",
    "    observation = np.zeros([len(h_states), len(v_states)])\n",
    "    for t in trajectories:\n",
    "        for i in range(len(t)):\n",
    "            s, o = t[i].split(\" \") # h and v come as a string \"h v\"\n",
    "            s_i, o_i = h_states.index(s), v_states.index(o)\n",
    "            if i == 0: # Prior\n",
    "                prior[s_i] += 1\n",
    "            else:\n",
    "                prev_s_i = h_states.index(t[i-1].split(\" \")[0])\n",
    "                transition[prev_s_i][s_i] += 1 # Transition\n",
    "            observation[s_i][o_i] += 1 # Observation\n",
    "\n",
    "    return normalize_cpd_values(['h0'], [len(h_states)], prior), \\\n",
    "           normalize_cpd_values(['ht-1', 'ht'], [len(h_states), len(h_states)], transition), \\\n",
    "           normalize_cpd_values(['ht', 'vt'], [len(h_states), len(v_states)], observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daFL8Gwu3Jxw"
   },
   "source": [
    "Then, we extract the probabilities from the training sequences, and print one sample trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zE-MW19f3Jxw",
    "outputId": "def5c7ef-d24d-4023-ec90-0f4fd0967265",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT: 401 robot trajectories read.\n",
      "['2:4', '3:4', '3:4', '4:4', '4:4', '4:4', '4:4', '4:4', '4:4', '3:4']\n",
      "['r', 'y', 'y', 'b', 'b', 'r', 'b', 'b', 'b', 'y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umutekingezer/opt/anaconda3/lib/python3.7/site-packages/pgmpy/factors/discrete/CPD.py:328: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tabular_cpd.values = (cpd / cpd.sum(axis=0)).reshape(tabular_cpd.cardinality)\n"
     ]
    }
   ],
   "source": [
    "with open(\"robot.data\") as f:\n",
    "    robot_data = f.read().splitlines() # this accounts for '\\n'\n",
    "\n",
    "# Split into train and test data (separated by \"..\" in the file, end of single trajectory is marked with \".\")\n",
    "train_robot, test_robot = [list(split(dataset, '.')) for dataset in split(robot_data, '..')]\n",
    "print(f\"ROBOT: {len(train_robot) + len(test_robot)} robot trajectories read.\")\n",
    "\n",
    "size_square = 4\n",
    "positions = [f\"{x+1}:{y+1}\" for x in range(size_square) for y in range(size_square)]\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "r_prior, r_transition, r_observation = get_hmm_factors(trajectories = train_robot,\n",
    "                                                       h_states=positions,\n",
    "                                                       v_states=colors) # This will raise a warning: invalid value encountered in true_divide\n",
    "\n",
    "# Define factor functions\n",
    "def robot_prior(pos):\n",
    "    return DiscreteFactor(variables=[pos],\n",
    "                          cardinality=[len(positions)],\n",
    "                          values=r_prior,\n",
    "                          state_names = {pos: positions})\n",
    "\n",
    "def robot_transition(prev_pos, next_pos):\n",
    "    return DiscreteFactor(variables=[prev_pos, next_pos],\n",
    "                          cardinality=[len(positions), len(positions)],\n",
    "                          values=r_transition,\n",
    "                          state_names = {prev_pos: positions,\n",
    "                                         next_pos: positions})\n",
    "\n",
    "def robot_observation(pos, col):\n",
    "    return DiscreteFactor(variables=[pos, col],\n",
    "                          cardinality=[len(positions), len(colors)],\n",
    "                          values=r_observation,\n",
    "                          state_names = {pos: positions,\n",
    "                                         col: colors})\n",
    "\n",
    "robot_pos_trajectories = [[f\"{p.split(' ')[0]}\" for p in traj] for traj in test_robot][:-1] # last one is empty\n",
    "robot_color_trajectories = [[f\"{p.split(' ')[1]}\" for p in traj] for traj in test_robot][:-1]\n",
    "\n",
    "print(robot_pos_trajectories[-1][:10])\n",
    "print(robot_color_trajectories[-1][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IdeX5Lt3Jxx"
   },
   "source": [
    "### Questions\n",
    "\n",
    "Given the following sequence of observations $v_{1:T}$:\n",
    "```\n",
    "['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
    "```\n",
    "\n",
    "Answer the following questions using your implementation of belief propagation:\n",
    "1. Filtering : what is $p(h_6|v_{1:6})$?\n",
    "2. Prediction : what is $p(h_7|v_{1:6})$?\n",
    "3. Probability of evidence : what is $p(v_{1:T})$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C9jRt42dlJF1"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "def prod(iterable):\n",
    "    \n",
    "    \"\"\"\n",
    "      Returns the product of all the items in the iterable given in as input.\n",
    "    \"\"\"\n",
    "\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "class MyBeliefPropagation:\n",
    "    def __init__(self, factor_graph):\n",
    "        assert factor_graph.check_model()\n",
    "        self.original_graph = factor_graph\n",
    "        self.variables = factor_graph.get_variable_nodes()\n",
    "        \n",
    "        self.state_names = dict()\n",
    "        for f in self.original_graph.factors:\n",
    "            self.state_names.update(f.state_names)\n",
    "        self.bp_done = False\n",
    "\n",
    "    def factor_ones(self, v):\n",
    "        \"\"\"\n",
    "        Returns a DiscreteFactor for variable v with all ones.\n",
    "        \"\"\"\n",
    "\n",
    "        return DiscreteFactor(variables=[v],\n",
    "                        cardinality=[len(self.state_names[v])],\n",
    "                        values=np.repeat(1.0,len(self.state_names[v])), \n",
    "                        state_names=self.state_names)\n",
    "        \n",
    "    def initialize_messages(self):\n",
    "        \"\"\"\n",
    "        This function creates, for each edge factor-variable, two messages: m(f->v) and \n",
    "        m(v->f). It initiliazies each message as a DiscreteFactor with all ones. It stores all\n",
    "        the messages in a dict of dict. Keys of both dicts are either factors or variables.\n",
    "        Messages are indexed as messages[to][from]. For example, m(x->y) is in messages[y][x].\n",
    "        It's done this way because it will be useful to get all messages that go to a variable\n",
    "        or a factor.\n",
    "        \"\"\"\n",
    "\n",
    "        self.messages = defaultdict(dict)\n",
    "        for fact in self.working_graph.get_factors():\n",
    "          if fact not in self.messages:\n",
    "            self.messages[fact] = dict()\n",
    "          for var in fact.variables:\n",
    "            if var not in self.messages:\n",
    "              self.messages[var] = dict() \n",
    "            self.messages[var][fact] = self.factor_ones(var)\n",
    "            self.messages[fact][var] = self.factor_ones(var)\n",
    "                \n",
    "    def factor_to_variable(self, f, v):\n",
    "        \"\"\"\n",
    "        Computes message m from factor to variable. It computes it from all messages from all\n",
    "        other variables to the factor (i.e. all variables connected the factor except v).\n",
    "        Returns message m.\n",
    "        \"\"\"\n",
    "        assert v in self.variables and f in self.working_graph.factors\n",
    "        variables = []\n",
    "        messages = []\n",
    "        for var in f.scope():\n",
    "            if var != v:\n",
    "                variables.append(var)\n",
    "                messages.append(self.messages[f][var])\n",
    "        \n",
    "        #We calculate the probability value: factors * prodfunc(messages)\n",
    "        m = f * prod(messages)\n",
    "        message = m.marginalize(variables, inplace = False)\n",
    "        return message\n",
    "        \n",
    "\n",
    "    def variable_to_factor(self, v, f):\n",
    "        \"\"\"\n",
    "        Computes message m from variable to factor. It computes it from all messages from all\n",
    "        other factors to the variable (i.e. all factors connected the variable except f).\n",
    "        Returns message m.\n",
    "        \"\"\"\n",
    "        assert v in self.variables and f in self.working_graph.factors\n",
    "        factors = []\n",
    "        for factor in self.messages[v]:\n",
    "          if f != factor: \n",
    "            factors.append(self.messages[v][factor])\n",
    "        m = prod(factors)\n",
    "        return m\n",
    "    \n",
    "    def get_evidence_factors(self, evidence):\n",
    "        \"\"\"\n",
    "        For each evidence variable v, create a factor with p(v=e)=1. Recieves a dict of\n",
    "        evidence, where keys are variables and values are variable states. Returns a list of\n",
    "        DiscreteFactor.\n",
    "        \"\"\"\n",
    "        evidences = []        \n",
    "        for variable in evidence:\n",
    "          factor = DiscreteFactor(variables = [variable],\n",
    "                                   cardinality = [len(self.state_names[variable])],\n",
    "                                   values = [float(state == evidence[variable]) for state in self.state_names[variable]], \n",
    "                                   state_names = self.state_names) \n",
    "          evidences.append(factor)\n",
    "        \n",
    "        return evidences\n",
    "        \n",
    "    def update(self, m_to, m_from):\n",
    "        \"\"\"\n",
    "        Performs an update of a message depending on whether it is variable-to-factor or\n",
    "        factor-to-variable.\n",
    "        \"\"\"\n",
    "        if m_from in self.working_graph.factors:\n",
    "          self.messages[m_to][m_from] = self.factor_to_variable(m_from,m_to)\n",
    "        else:\n",
    "          self.messages[m_to][m_from] = self.variable_to_factor(m_from,m_to)\n",
    "        \n",
    "\n",
    "    \n",
    "    def collect_evidence(self, node, parent=None):\n",
    "        \"\"\"\n",
    "        Passes messages from the leaves to the root of the tree.\n",
    "        The parent argument is used to avoid an infinite recursion.\n",
    "        \"\"\"\n",
    "        for child in self.working_graph.neighbors(node):\n",
    "          if child != parent:\n",
    "            self.update(node,self.collect_evidence(child,node))\n",
    "        return node \n",
    "\n",
    "    def distribute_evidence(self, node, parent=None):\n",
    "        \"\"\"\n",
    "        Passes messages from the root to the leaves of the tree.\n",
    "        The parent argument is used to avoid an infinite recursion.\n",
    "        \"\"\"\n",
    "        for child in self.working_graph.neighbors(node):\n",
    "          if child != parent:\n",
    "            self.update(child,node)\n",
    "            self.distribute_evidence(child,node)\n",
    "    \n",
    "    def set_evidence(self, evidence):\n",
    "        \"\"\"\n",
    "        Generates a new graph with the evidence factors\n",
    "        evidence (keys: variables, values: states)\n",
    "        \"\"\"\n",
    "        evidence_factors = self.get_evidence_factors(evidence)\n",
    "        self.working_graph = self.original_graph.copy()\n",
    "        for factor in evidence_factors:\n",
    "          self.working_graph.add_factors(factor)\n",
    "          for vars in factor.variables:\n",
    "            self.working_graph.add_edge(factor,vars)\n",
    "\n",
    "        self.bp_done = False\n",
    "    \n",
    "    def run_bp(self, root):\n",
    "        \"\"\"\n",
    "        After initializing the messages, this function performs Belief Propagation\n",
    "        using collect_evidence and distribute_evidence from the given root node.\n",
    "        \"\"\"\n",
    "        assert root in self.variables, \"Variable not in the model\"\n",
    "        self.initialize_messages()\n",
    "        self.collect_evidence(root)\n",
    "        self.distribute_evidence(root)\n",
    "        self.bp_done = True\n",
    "\n",
    "    def get_marginal(self, variable):\n",
    "        \"\"\"\n",
    "        To be used after run_bp. Returns p(variable | evidence) unnormalized.\n",
    "        \"\"\"\n",
    "        assert self.bp_done, \"First run BP!\"\n",
    "        probs = []\n",
    "        for msg in self.messages[variable]:\n",
    "          probs.append(self.messages[variable][msg])\n",
    "        return prod(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c9808d6086d24640b36b8509292a28b5",
      "ce9dfff3d6874d50ab0d409703c4b438",
      "176bea0bc3d14dd587bbd31a70bbefad",
      "c314412f3b8d433a84781822dc1179e1",
      "a99fcb6a400e4940992300f86f5f511f",
      "d2dfc0b53ccc4d52979b8a5b1fe9d3b6",
      "6dcf022d089042e3a7bb68b4a220293b",
      "33d6462d848a4bb395b061f3e3cfe0f5",
      "075a54fdf0044a35b7fd840ceb248c7a",
      "a0b3c38228d6444d8b7ef87c7adbb9b7",
      "e7d451aea51d469d90e74a9dd62dd30e"
     ]
    },
    "id": "yttkmfJywRFN",
    "outputId": "325d7c75-1ae3-4017-8935-f707ac923a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "| position5      |   phi(position5) |\n",
      "+================+==================+\n",
      "| position5(1:1) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position5(1:2) |           0.0109 |\n",
      "+----------------+------------------+\n",
      "| position5(1:3) |           0.0039 |\n",
      "+----------------+------------------+\n",
      "| position5(1:4) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position5(2:1) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position5(2:2) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position5(2:3) |           0.8905 |\n",
      "+----------------+------------------+\n",
      "| position5(2:4) |           0.0353 |\n",
      "+----------------+------------------+\n",
      "| position5(3:1) |           0.0002 |\n",
      "+----------------+------------------+\n",
      "| position5(3:2) |           0.0081 |\n",
      "+----------------+------------------+\n",
      "| position5(3:3) |           0.0092 |\n",
      "+----------------+------------------+\n",
      "| position5(3:4) |           0.0267 |\n",
      "+----------------+------------------+\n",
      "| position5(4:1) |           0.0006 |\n",
      "+----------------+------------------+\n",
      "| position5(4:2) |           0.0002 |\n",
      "+----------------+------------------+\n",
      "| position5(4:3) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position5(4:4) |           0.0143 |\n",
      "+----------------+------------------+\n",
      "Maximum probability: 0.8904536189223202\n",
      "State assignment: [('position5', '2:3')]\n",
      "+----------------+------------------+\n",
      "| position6      |   phi(position6) |\n",
      "+================+==================+\n",
      "| position6(1:1) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position6(1:2) |           0.0093 |\n",
      "+----------------+------------------+\n",
      "| position6(1:3) |           0.2293 |\n",
      "+----------------+------------------+\n",
      "| position6(1:4) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position6(2:1) |           0.0001 |\n",
      "+----------------+------------------+\n",
      "| position6(2:2) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position6(2:3) |           0.2407 |\n",
      "+----------------+------------------+\n",
      "| position6(2:4) |           0.2473 |\n",
      "+----------------+------------------+\n",
      "| position6(3:1) |           0.0022 |\n",
      "+----------------+------------------+\n",
      "| position6(3:2) |           0.0045 |\n",
      "+----------------+------------------+\n",
      "| position6(3:3) |           0.2248 |\n",
      "+----------------+------------------+\n",
      "| position6(3:4) |           0.0220 |\n",
      "+----------------+------------------+\n",
      "| position6(4:1) |           0.0004 |\n",
      "+----------------+------------------+\n",
      "| position6(4:2) |           0.0023 |\n",
      "+----------------+------------------+\n",
      "| position6(4:3) |           0.0000 |\n",
      "+----------------+------------------+\n",
      "| position6(4:4) |           0.0173 |\n",
      "+----------------+------------------+\n",
      "Maximum probability: 0.24726581399311356\n",
      "State assignment: [('position6', '2:4')]\n",
      "Probability of evidence p(v1:15) 1.083161412279158e-08\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-02c7ff654b78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#comparing with the given BP to debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"position5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'color0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'color1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'color2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'color3'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'color4'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'color5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'b'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mamax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pgmpy/inference/ExactInference.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, variables, evidence, virtual_evidence, joint, show_progress)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mevidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevidence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mjoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         )\n\u001b[1;32m   1021\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pgmpy/inference/ExactInference.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, variables, operation, evidence, joint, show_progress)\u001b[0m\n\u001b[1;32m    888\u001b[0m             root_node = tuple(\n\u001b[1;32m    889\u001b[0m                 \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             )[0]\n\u001b[0m\u001b[1;32m    891\u001b[0m         \u001b[0mclique_potential_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclique_beliefs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "observed_colors = ['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
    "\n",
    "robot_HMM = HMM(n_vars=len(observed_colors),\n",
    "                prior_fn=robot_prior,\n",
    "                transition_fn=robot_transition,\n",
    "                observation_fn=robot_observation,\n",
    "                h_states=positions,\n",
    "                v_states=colors,\n",
    "                h_name=\"position\",\n",
    "                v_name=\"color\")\n",
    "\n",
    "\n",
    "robot_bp = MyBeliefPropagation(robot_HMM.to_factor_graph())\n",
    "#Evidences\n",
    "robot_bp.set_evidence({\"color0\":\"g\",\"color1\":\"g\",\"color2\":\"b\",\"color3\":\"r\",\"color4\":\"r\",\"color5\":\"b\"})\n",
    "robot_bp.run_bp(\"position0\")\n",
    "\n",
    "#We get the marginals and the state assignments (highest probability)\n",
    "#filtering\n",
    "filtering = robot_bp.get_marginal(\"position5\").normalize(inplace=False)\n",
    "mymax = np.argmax(filtering.values)\n",
    "print(filtering)\n",
    "print(\"Maximum probability:\", filtering.values.flatten()[mymax])\n",
    "print(\"State assignment:\", sorted(filtering.assignment([mymax])[0]))\n",
    "\n",
    "#prediction \n",
    "predict = robot_bp.get_marginal(\"position6\").normalize(inplace=False)\n",
    "print(predict)\n",
    "mymax2 = np.argmax(predict.values)\n",
    "print(\"Maximum probability:\", predict.values.flatten()[mymax2])\n",
    "print(\"State assignment:\", sorted(predict.assignment([mymax2])[0]))\n",
    "\n",
    "#Probability of evidence p(v1:15)\n",
    "robot_bp2 = MyBeliefPropagation(robot_HMM.to_factor_graph())\n",
    "robot_bp2.set_evidence({\"color0\":\"g\",\"color1\":\"g\",\"color2\":\"b\",\"color3\":\"r\",\"color4\":\"r\",\"color5\":\"b\",\n",
    "                     \"color6\":\"b\",\"color7\":\"r\",\"color8\":\"r\",\"color9\":\"y\",\"color10\":\"r\",\"color11\":\"b\",\n",
    "                     \"color12\":\"r\",\"color13\":\"y\",\"color14\":\"b\"})\n",
    "\n",
    "robot_bp2.run_bp(\"position0\")\n",
    "prob = robot_bp2.get_marginal(\"position3\")\n",
    "print(\"Probability of evidence p(v1:15)\",np.sum(prob.values))\n",
    "\n",
    "#comparing with the given BP to debug\n",
    "\n",
    "q1 = bp.query(variables=\"position5\", evidence={'color0':'g','color1':'g','color2':'b', 'color3':'r','color4':'b','color5':'b' })\n",
    "print(q1)\n",
    "amax = np.argmax(q1.values)\n",
    "print(\"Maximum probability:\", q1.values.flatten()[amax])\n",
    "print(\"State assignment:\", sorted(q1.assignment([amax])[0]))\n",
    "\n",
    "#We have the tuple index error but we have the result,the error does not have any influence on the results.\n",
    "\n",
    "#raise IndexError (\"tuple index out of range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_149nsY3Jxy"
   },
   "source": [
    "#### SOLUTION:\n",
    "Original trajectory:\n",
    "```\n",
    "robot_pos_trajectories[9][:15]\n",
    "['1:3', '1:3', '2:3', '2:4', '2:4', '2:3', '2:3', '2:4', '2:4', '3:4', '3:3', '2:3', '2:4', '3:4', '4:4']\n",
    "['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKjFRhMx3Jxz"
   },
   "source": [
    "## Task 2: Correcting typos without a dictionary\n",
    "\n",
    "The second domain deals with the problem of correcting typos in text without using a dictionary.  Here, you will be given text containing many typographical errors and the goal is to correct as many typos as possible.\n",
    "\n",
    "In this problem, state refers to the correct letter that should have been typed, and output refers to the actual letter that was typed.  Given a sequence of outputs (i.e., actually typed letters), the problem is to reconstruct the hidden state sequence (i.e., the intended sequence of letters).  Thus, data for this problem looks like this:\n",
    "\n",
    "<code>\n",
    "i i\n",
    "n n \n",
    "t t\n",
    "r r\n",
    "o o\n",
    "d x\n",
    "u u\n",
    "c c\n",
    "t t\n",
    "i i\n",
    "o i\n",
    "n n\n",
    "_ _\n",
    "t t\n",
    "h h\n",
    "e e\n",
    "_ _\n",
    "</code>\n",
    "\n",
    "\n",
    "where the left column is the correct text and the right column contains text with errors.\n",
    "\n",
    "Data for this problem was generated as follows: we started with a text document, in this case, the Unabomber's Manifesto, which was chosen not for political reasons, but as a convenient, on-line, single-author text of about the right length.  For simplicity, all numbers and punctuation were converted to white space and all letters converted to lower case.  The remaining text is a sequence only over the lower case letters and the space character, represented in the data files by an underscore character.  Next, typos were artificially added to the data as follows: with $90\\%$ probability, the correct letter is transcribed, but with $10\\%$ probability, a randomly chosen neighbor (on an ordinary physical keyboard) of the letter is transcribed instead.  Space characters are always transcribed correctly.  In a harder variant of the problem, the rate of errors is increased to $20\\%$.  The first (roughly) $20,000$ characters of the document have been set aside for testing.  The remaining $161,000$ characters are used for training.\n",
    "\n",
    "As an example, the original document begins:\n",
    "\n",
    "<code>introduction the industrial revolution and its consequences have been a disaster for the human race they have greatly increased the life expectancy of those of us who live in advanced countries but they have destabilized society\n",
    "</code>    \n",
    "    \n",
    "With $20\\%$ noise, it looks like this:\n",
    "\n",
    "<code>introductipn the industfial revolhtjon and its consequences bafw newn a diszster rkr the yumab race thdy have grwatky increased the ljte esoectandy od thosr of is who libe in advanced coubfries but they have fewtabipuzee xociwty</code>\n",
    "\n",
    "The error rate (fraction of  characters that are mistyped) is about $16.5\\%$ (less than $20\\%$ because space characters were not corrupted).\n",
    "\n",
    "Data for this part of the assignment is in [typos10.data](files/typos10.data) and [typos20.data](files/typos20.data), representing data generated with a $10\\%$ or $20\\%$ error rate, respectively.\n",
    "\n",
    "Next, we provide the code to get the HMM from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LVmFTP5d3Jxz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPOS 10: 30558 words read.\n",
      "TYPOS 20: 30558 words read.\n",
      "Original text:  introduction the industrial revolution and its consequences have been a disaster for the human \n",
      "Typos 10% text: introxuctiin the ibdudtrial revokufuon anf its consequences ysfe been a disaster for the hyman \n",
      "Typos 20% text: introductipn the industfial revolhtjon and its consequences bafw newn a diszster rkr the yumab \n"
     ]
    }
   ],
   "source": [
    "# 10% error rate\n",
    "with open(\"typos10.data\") as f:\n",
    "    text_data = f.read().splitlines() # this accounts for '\\n'\n",
    "\n",
    "# Split into train and test data (separated by \"..\" in the file, end of single word is marked with \"_ _\")\n",
    "train_typos10, test_typos10 = [list(split(dataset, '_ _')) for dataset in split(text_data, '..')]\n",
    "print(f\"TYPOS 10: {len(train_typos10) + len(test_typos10)} words read.\")\n",
    "\n",
    "characters = [chr(i+97) for i in range(26)]\n",
    "t10_prior, t10_transition, t10_observation = get_hmm_factors(trajectories = train_typos10,\n",
    "                                                             h_states=characters,\n",
    "                                                             v_states=characters)\n",
    "\n",
    "# 20% error rate\n",
    "with open(\"typos20.data\") as f:\n",
    "    text_data = f.read().splitlines() # this accounts for '\\n'\n",
    "train_typos20, test_typos20 = [list(split(dataset, '_ _')) for dataset in split(text_data, '..')]\n",
    "print(f\"TYPOS 20: {len(train_typos20) + len(test_typos20)} words read.\")\n",
    "t20_prior, t20_transition, t20_observation = get_hmm_factors(trajectories = train_typos20,\n",
    "                                                             h_states=characters,\n",
    "                                                             v_states=characters)\n",
    "\n",
    "# Define factor functions\n",
    "def text10_prior(c):\n",
    "    return DiscreteFactor(variables=[c],\n",
    "                          cardinality=[len(characters)],\n",
    "                          values=t10_prior,\n",
    "                          state_names = {c: characters})\n",
    "\n",
    "def text10_transition(prev_c, next_c):\n",
    "    return DiscreteFactor(variables=[prev_c, next_c],\n",
    "                          cardinality=[len(characters), len(characters)],\n",
    "                          values=t10_transition,\n",
    "                          state_names = {prev_c: characters,\n",
    "                                         next_c: characters})\n",
    "\n",
    "def text10_observation(c, c_typed):\n",
    "    return DiscreteFactor(variables=[c, c_typed],\n",
    "                          cardinality=[len(characters), len(characters)],\n",
    "                          values=t10_observation,\n",
    "                          state_names = {c: characters,\n",
    "                                         c_typed: characters})\n",
    "\n",
    "def text20_prior(c):\n",
    "    return DiscreteFactor(variables=[c],\n",
    "                          cardinality=[len(characters)],\n",
    "                          values=t20_prior,\n",
    "                          state_names = {c: characters})\n",
    "\n",
    "def text20_transition(prev_c, next_c):\n",
    "    return DiscreteFactor(variables=[prev_c, next_c],\n",
    "                          cardinality=[len(characters), len(characters)],\n",
    "                          values=t20_transition,\n",
    "                          state_names = {prev_c: characters,\n",
    "                                         next_c: characters})\n",
    "\n",
    "def text20_observation(c, c_typed):\n",
    "    return DiscreteFactor(variables=[c, c_typed],\n",
    "                          cardinality=[len(characters), len(characters)],\n",
    "                          values=t20_observation,\n",
    "                          state_names = {c: characters,\n",
    "                                         c_typed: characters})\n",
    "\n",
    "# Get test text from dataset\n",
    "original_text = \" \".join([\"\".join([c.split(\" \")[0] for c in word]) for word in test_typos10])\n",
    "typos10_text = \" \".join([\"\".join([c.split(\" \")[1] for c in word]) for word in test_typos10])\n",
    "typos20_text = \" \".join([\"\".join([c.split(\" \")[1] for c in word]) for word in test_typos20])\n",
    "print(\"Original text: \", original_text[:95])\n",
    "print(\"Typos 10% text:\", typos10_text[:95])\n",
    "print(\"Typos 20% text:\", typos20_text[:95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIGeK_1B3Jx0"
   },
   "source": [
    "### Questions\n",
    "\n",
    "Given the following sequence of observations $v_{1:T}$:\n",
    "```\n",
    "['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
    "```\n",
    "\n",
    "Answer the following questions:\n",
    "1. Filtering : what is $p(h_{11}|v_{1:11})$?\n",
    "2. Prediction : what is $p(h_{12}|v_{1:11})$?\n",
    "3. Probability of evidence : what is $p(v_{1:12})$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "x62ue_Kt3Jx0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering p(h11|v1:11): +--------+------------+\n",
      "| c10    |   phi(c10) |\n",
      "+========+============+\n",
      "| c10(a) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(b) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(c) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(d) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(e) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(f) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(g) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(h) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(i) |     0.1140 |\n",
      "+--------+------------+\n",
      "| c10(j) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(k) |     0.0602 |\n",
      "+--------+------------+\n",
      "| c10(l) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(m) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(n) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(o) |     0.8078 |\n",
      "+--------+------------+\n",
      "| c10(p) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(q) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(r) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(s) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(t) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(u) |     0.0179 |\n",
      "+--------+------------+\n",
      "| c10(v) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(w) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(x) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(y) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c10(z) |     0.0000 |\n",
      "+--------+------------+\n",
      "Prediction p(h12|v1:11): +--------+------------+\n",
      "| c11    |   phi(c11) |\n",
      "+========+============+\n",
      "| c11(a) |     0.0122 |\n",
      "+--------+------------+\n",
      "| c11(b) |     0.0137 |\n",
      "+--------+------------+\n",
      "| c11(c) |     0.0461 |\n",
      "+--------+------------+\n",
      "| c11(d) |     0.0248 |\n",
      "+--------+------------+\n",
      "| c11(e) |     0.0445 |\n",
      "+--------+------------+\n",
      "| c11(f) |     0.0876 |\n",
      "+--------+------------+\n",
      "| c11(g) |     0.0334 |\n",
      "+--------+------------+\n",
      "| c11(h) |     0.0008 |\n",
      "+--------+------------+\n",
      "| c11(i) |     0.0243 |\n",
      "+--------+------------+\n",
      "| c11(j) |     0.0000 |\n",
      "+--------+------------+\n",
      "| c11(k) |     0.0023 |\n",
      "+--------+------------+\n",
      "| c11(l) |     0.0645 |\n",
      "+--------+------------+\n",
      "| c11(m) |     0.0547 |\n",
      "+--------+------------+\n",
      "| c11(n) |     0.1787 |\n",
      "+--------+------------+\n",
      "| c11(o) |     0.0211 |\n",
      "+--------+------------+\n",
      "| c11(p) |     0.0323 |\n",
      "+--------+------------+\n",
      "| c11(q) |     0.0003 |\n",
      "+--------+------------+\n",
      "| c11(r) |     0.1265 |\n",
      "+--------+------------+\n",
      "| c11(s) |     0.0498 |\n",
      "+--------+------------+\n",
      "| c11(t) |     0.0545 |\n",
      "+--------+------------+\n",
      "| c11(u) |     0.0672 |\n",
      "+--------+------------+\n",
      "| c11(v) |     0.0205 |\n",
      "+--------+------------+\n",
      "| c11(w) |     0.0354 |\n",
      "+--------+------------+\n",
      "| c11(x) |     0.0004 |\n",
      "+--------+------------+\n",
      "| c11(y) |     0.0031 |\n",
      "+--------+------------+\n",
      "| c11(z) |     0.0014 |\n",
      "+--------+------------+\n",
      "Probability evidence of p(v1:12) 3.009213468222274e-15\n"
     ]
    }
   ],
   "source": [
    "word = ['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
    "\n",
    "\n",
    "# the ['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
    "\n",
    "word_hmm = HMM(n_vars=len(word),\n",
    "               prior_fn=text10_prior,\n",
    "               transition_fn=text10_transition,\n",
    "               observation_fn=text10_observation,\n",
    "               h_states=characters,\n",
    "               v_states=characters,\n",
    "               h_name=\"c\",\n",
    "               v_name=\"c_typed\")\n",
    "\n",
    "# ...\n",
    "\n",
    "#\n",
    "typo_bp = MyBeliefPropagation(word_hmm.to_factor_graph())\n",
    "#First the evidences are set\n",
    "typo_bp.set_evidence({\"c_typed0\":'i',\"c_typed1\":'n',\"c_typed2\":'t',\n",
    "                                            \"c_typed3\":'r',\"c_typed4\":'o',\"c_typed5\":'x',\n",
    "                                           \"c_typed6\":'u',\"c_typed7\":'c',\"c_typed8\":'t',\n",
    "                                           \"c_typed9\":'i',\"c_typed10\":'i'})\n",
    "#Belief Propagation is running.. c0:initial\n",
    "typo_bp.run_bp(\"c0\")\n",
    "#filtering for the   𝑝(ℎ11|𝑣1:11): \n",
    "filtering = typo_bp.get_marginal(\"c10\").normalize(inplace=False)\n",
    "print(\"Filtering p(h11|v1:11):\",filtering)\n",
    "#Prediction for the 𝑝(ℎ12|𝑣1:11):\n",
    " \n",
    "prediction = typo_bp.get_marginal(\"c11\").normalize(inplace=False)\n",
    "print(\"Prediction p(h12|v1:11):\", prediction)\n",
    "\n",
    "#Probability of evidence task:\n",
    "\n",
    "typo_bp2 = MyBeliefPropagation(word_hmm.to_factor_graph())\n",
    "\n",
    "typo_bp2.set_evidence({\"c_typed0\":'i',\"c_typed1\":'n',\"c_typed2\":'t',\n",
    "                                            \"c_typed3\":'r',\"c_typed4\":'o',\"c_typed5\":'x',\n",
    "                                           \"c_typed6\":'u',\"c_typed7\":'c',\"c_typed8\":'t',\n",
    "                                           \"c_typed9\":'i',\"c_typed10\":'i'})\n",
    "\n",
    "#Belief Propagation is running.. c0:initial\n",
    "typo_bp2.run_bp(\"c10\")\n",
    "#Chosen randomly c10 to marginalization:\n",
    "probability = typo_bp2.get_marginal(\"c10\")\n",
    "prob_evindence=np.sum(probability.values)\n",
    "print(\"Probability evidence of p(v1:12)\",prob_evindence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCHTwbdC3Jx1"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "`# This is formatted as code`\n",
    "```\n",
    "\n",
    "## The Viterbi algorithm\n",
    "\n",
    "We have seen how we can obtain the MAP query from a BP query, and how that approach did not scale. Let's implement now the Viterbi algorithm to perform MAP queries on a HMM. It consists of the following steps\n",
    "\n",
    "1. Compute the factors $\\mu_t$ that will recursively be used to obtain the maximum probability\n",
    "\n",
    "$$\\mu(h_{t-1}) = \\max_{h_t} p(v_t|h_t)p(h_t|h_{t-1})\\mu(h_t),\\qquad 2\\leq t\\leq T,$$\n",
    "$$\\mu(h_T) = 1.$$\n",
    "\n",
    "2. Obtain the desired maximum probability and backtrack to obtain the state trajectory $h^*_{1:T}$ using the previous computations\n",
    "\n",
    "$$p_\\text{max} = \\text{max}_{h_1} p(v_1|h_1)p(h_1)\\mu(h_1),$$\n",
    "$$h_1^* = \\text{argmax}_{h_1} p(v_1|h_1)p(h_1)\\mu(h_1),$$\n",
    "$$h_t^* = \\text{argmax}_{h_t} p(v_t|h_t)p(h_t|h_{t-1}^*)\\mu(h_t).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nXaJCWPr3Jx1"
   },
   "outputs": [],
   "source": [
    "def factor_ones(v, state_names):\n",
    "    \"\"\"\n",
    "    Returns a DiscreteFactor with all ones for variable v with its domain defined in states_names.\n",
    "    \"\"\"\n",
    "    card = len(state_names[v])\n",
    "    return DiscreteFactor(variables=[v],\n",
    "                          cardinality=[card],\n",
    "                          values=np.ones(card),\n",
    "                          state_names=state_names)\n",
    "\n",
    "class Viterbi:\n",
    "    def max_and_argmax(self, f):\n",
    "        \"\"\"\n",
    "        Given a factor f, returns its maximum value and the corresponding assignment. We assume that f\n",
    "        is a DiscreteFactor of one variable.\n",
    "        \"\"\"\n",
    "        assert len(f.variables)==1, \"Factor connected to more than one variable: \"+str(f.variables)\n",
    "        v = f.variables[0]\n",
    "        am = np.argmax(f.values)\n",
    "        return f.values[am], list(f.state_names[v])[am]\n",
    "    \n",
    "    def compute_messages(self, hmm, evidence):\n",
    "        \"\"\"\n",
    "        Given an HMM and the evidence (a list of states in order from left to right), compute the\n",
    "        messages (from right to left).\n",
    "        Returns a list of messages.\n",
    "        \"\"\"\n",
    "        n_vars = len(evidence)\n",
    "        messages = [None]*n_vars\n",
    "        \n",
    "        #https://jessicastringham.net/2018/05/13/viterbi-message-passing/\n",
    "        # IMPLEMENT\n",
    "        #gegeben: HMM, evidence(left to right)\n",
    "        #gesucht: message (right to left)\n",
    "        #REMEMBER:.reverse() function should be used at the end \n",
    "        \n",
    "        #We start with last message to first one, thus reverse iteration is required.\n",
    "        \n",
    "        last_index=(len(hmm.h)-1) #last_index: t-1, first index=0\n",
    "        \n",
    "        \n",
    "        for index in range(last_index,-1,-1):\n",
    "            \n",
    "            if index==last_index:\n",
    "                #u(ht)=1\n",
    "                \n",
    "                messages[index]=1 \n",
    "                \n",
    "            else:\n",
    "                #u(ht-1)= maxht[p(vt|ht)*p(ht|ht-1)*u(ht)]\n",
    "                \n",
    "                ht     = hmm.f[(hmm.h[index+1]),(hmm.v[index+1])] # p(vt|ht)\n",
    "                ht_1   = hmm.f[(hmm.h[index]),(hmm.h[index+1])]   # p(ht|ht-1)\n",
    "                ut     = messages[index+1]                    # u(ht)\n",
    "                \n",
    "                \n",
    "                multiplication= (ht)*(ht_1)*(messages[index+1])   \n",
    "                \n",
    "                #Time to reduce discrete factors according to given evidences vt:\n",
    "                \n",
    "                reduced_multiplication= multiplication.reduce([(hmm.v[index+1],evidence[index+1])],inplace=False)\n",
    "                \n",
    "                \n",
    "                #Then self.maximize and save in messages[index]:\n",
    "                \n",
    "                messages[index]= reduced_multiplication.maximize([hmm.h[index+1]],inplace=False)\n",
    "                \n",
    "               \n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "        assert all(m is not None for m in messages)\n",
    "        messages.reverse()\n",
    "        return messages\n",
    "    \n",
    "    def backtrack(self, hmm, messages, evidence):\n",
    "        \"\"\"\n",
    "        Given an HMM, the messages (computed from right to left), and the evidence (a list of states\n",
    "        in order from left to right), it computes the MAP states as well as their value in the joint\n",
    "        distribution.\n",
    "        Returns a list of states and the joint probability of these states.\n",
    "        \"\"\"\n",
    "        #IMPLEMENT: h0, compute MAP value\n",
    "        \n",
    "        #given: HMM,the messages (computed from right to left),evidence (a list of states in order from left to right)\n",
    "        #return:a list of states and the joint probability of these states.\n",
    "        \n",
    "        #Make the message reverse\n",
    "        messages.reverse()\n",
    "        \n",
    "        #value, h0_opt =\n",
    "        \n",
    "        #map_h=[]\n",
    "        \n",
    "        #Initialize first likely state #u(ht-1)= maxht[p(v0|h0)*p(h0)*u(h0)]\n",
    "        \n",
    "        initial=hmm.f[hmm.h[0],hmm.v[0]]*hmm.f[hmm.h[0]]* messages[0] \n",
    "        \n",
    "        #Reducing discrete factor according to given first evidences:\n",
    "        \n",
    "        reduced_initial=initial.reduce([(hmm.v[0],evidence[0])],inplace=0)\n",
    "        \n",
    "        #We have had alread argmax function in the Class viterbi\n",
    "        \n",
    "        h0_value,h0_opt=self.max_and_argmax(reduced_initial)\n",
    "        \n",
    "        \n",
    "        \n",
    "        value=h0_value      \n",
    "        map_h = [h0_opt]\n",
    "        \n",
    "        #0 index values are already implemented in above,Now we implement in general:\n",
    "        \n",
    "        for t in range(1, len(hmm.h)):\n",
    "            \n",
    "             #u(ht-1)= maxht[p(vt|ht)*p(ht|ht-1)*u(ht)\n",
    "            \n",
    "        \n",
    "            multiplication=hmm.f[hmm.h[t],hmm.v[t]]*hmm.f[hmm.h[t-1],hmm.h[t]]* messages[t]\n",
    "            reduced_multiplication=multiplication.reduce([(hmm.v[t],evidence[t]),(hmm.h[t-1],map_h[t-1])],inplace=False)\n",
    "            h_value,h_opt=self.max_and_argmax(reduced_multiplication)\n",
    "            \n",
    "            #Here is the map_h list which is define before the iteration, the optimum trajectories appended inside:\n",
    "            map_h.append(h_opt)\n",
    "            #\n",
    "            value=h_value\n",
    "            map_h.append(h_opt)\n",
    "        return map_h, value\n",
    "    \n",
    "    def map_query(self, hmm, evidence):\n",
    "        \"\"\"\n",
    "        Given an hmm and the evidence (a list of states in order from left to right), returns the\n",
    "        MAP states as well as the MAP probability.\n",
    "        \"\"\"\n",
    "        assert type(evidence) in (list, tuple), \"The evidence should be a list of observed states\"\n",
    "        assert len(evidence) == len(hmm.v), \"To get the MAP of the states we need the whole sequence of observed states\"\n",
    "        messages = self.compute_messages(hmm, evidence)\n",
    "        return self.backtrack(hmm, messages, evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "719oapWn3Jx2"
   },
   "source": [
    "### MAP queries in the Basic setting\n",
    "First we try it in our simple setting, and check that the result is the same as from the BP query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xCxAtCNe3Jx2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP states: ['rainy', 'cloudy', 'cloudy', 'rainy', 'rainy']\n",
      "MAP prob: 0.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Maximum probability: 0.16289702507051773\\nState assignment: [('w0', 'rainy'), ('w1', 'cloudy'), ('w2', 'rainy')]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi = Viterbi()\n",
    "map_states, map_prob = viterbi.map_query(hmm_weather_3, evidence=[True, True, True])\n",
    "print(\"MAP states:\", map_states)\n",
    "print(\"MAP prob:\", map_prob)\n",
    "\n",
    "\"\"\"Maximum probability: 0.16289702507051773\n",
    "State assignment: [('w0', 'rainy'), ('w1', 'cloudy'), ('w2', 'rainy')]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBcsE2JC3Jx3"
   },
   "source": [
    "How does this method compare, in terms of complexity, to our previous, naive, approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIsNoBeh3Jx3"
   },
   "source": [
    "Viterbi method:\n",
    "MAP states: ['rainy', 'cloudy', 'cloudy', 'rainy', 'rainy']\n",
    "MAP prob: 0.38\n",
    "\n",
    "\n",
    "\n",
    "Belief Propagation:\n",
    "Maximum probability: 0.16289702507051773\n",
    "State assignment: [('w0', 'rainy'), ('w1', 'cloudy'), ('w2', 'rainy')]\n",
    "\n",
    "#Viterbi algorithm has greater probability then Belief Propagation and has more states then previouse algorithm. So we can suggest that Viterbi algorithm is more sensitive and complex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ9i7HfW3Jx4"
   },
   "source": [
    "### MAP queries in the robot navigation setting\n",
    "\n",
    "To try it in the robot navigation setting, let's first define the DiscreteFactor functions for the HMM model, according to the values extracted from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hZAEqXNA3Jx4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traj: ['g', 'g', 'r', 'r', 'g', 'r', 'g', 'g', 'r', 'r', 'g', 'r', 'r', 'r', 'r', 'r', 'g', 'r', 'b', 'g', 'g', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'b', 'y', 'r', 'g', 'r', 'r', 'g', 'g', 'r', 'r', 'r', 'r', 'r', 'g', 'g', 'g', 'b', 'b', 'r', 'b', 'g', 'g', 'g', 'g', 'g', 'y', 'b', 'b', 'y', 'g', 'y', 'y', 'y', 'b', 'y', 'g', 'y', 'g', 'g', 'r', 'b', 'g', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'g', 'g', 'b', 'r', 'r', 'r', 'b', 'r', 'y', 'y', 'g', 'g', 'b', 'r', 'r', 'b', 'g', 'b', 'g', 'r', 'y', 'r', 'y', 'b', 'g', 'r', 'b', 'r', 'y', 'b', 'y', 'y', 'r', 'g', 'b', 'y', 'y', 'y', 'g', 'b', 'y', 'b', 'b', 'b', 'y', 'g', 'y', 'b', 'y', 'g', 'y', 'y', 'b', 'b', 'y', 'y', 'y', 'b', 'b', 'y', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'y', 'y', 'y', 'r', 'y', 'y', 'g', 'y', 'y', 'r', 'g', 'g', 'b', 'b', 'b', 'b', 'b', 'b', 'y', 'y', 'y', 'g', 'r', 'b', 'g', 'g', 'g', 'g', 'g', 'b', 'r', 'b', 'b', 'b', 'g', 'g', 'b', 'r', 'b', 'r', 'b', 'g', 'y', 'b']\n",
      "Infered traj.:  ['1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '2:3', '2:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '2:3', '2:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '2:3', '2:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '1:2', '1:2', '2:3', '2:3', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '3:3', '3:3', '3:3', '3:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3']\n",
      "Solution:       ['1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '2:3', '2:3', '3:3', '3:2', '3:2', '3:2', '3:2', '3:2', '3:2', '4:2', '4:1', '4:1', '3:1', '3:2', '4:2', '4:2', '4:2', '4:1', '3:1', '2:1', '3:1', '3:2', '3:2', '3:3', '2:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '2:3', '2:4', '2:4', '2:4', '2:4', '2:4', '2:3', '1:3', '1:3', '1:3', '2:3', '2:4', '2:4', '2:3', '1:3', '2:3', '3:3', '3:3', '3:4', '3:3', '3:4', '3:3', '3:2', '3:3', '2:3', '2:4', '3:4', '4:4', '3:4', '3:4', '3:3', '3:2', '4:2', '4:2', '4:2', '4:2', '4:1', '4:1', '3:1', '4:1', '4:1', '4:1', '3:1', '2:1', '3:1', '4:1', '3:1', '3:2', '3:1', '3:1', '4:1', '4:1', '4:2', '4:2', '4:2', '4:1', '4:1', '3:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:2', '4:2', '4:2', '4:1', '4:2', '4:2', '4:2', '4:2', '4:2', '4:2', '3:2', '4:2', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:2', '4:2', '4:2', '3:2', '3:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:4', '2:3', '2:3', '2:3', '1:3', '1:3', '2:3', '2:4', '2:3', '3:3', '2:3', '1:3', '2:3', '2:3']\n",
      "MAP value: 0.2373142165409162\n",
      "Map states: ['1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '2:3', '2:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '2:3', '2:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '2:3', '2:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '1:2', '1:2', '2:3', '2:3', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '1:2', '1:2', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3', '2:3', '2:3', '2:3', '2:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '3:3', '3:3', '3:3', '3:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '2:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '2:3', '2:3']\n",
      "Error: 0.39598997493734334\n"
     ]
    }
   ],
   "source": [
    "observed_colors = robot_color_trajectories[4]\n",
    "actual_trajectory = robot_pos_trajectories[4]\n",
    "\n",
    "robot_HMM = HMM(n_vars=len(observed_colors),\n",
    "                prior_fn=robot_prior,\n",
    "                transition_fn=robot_transition,\n",
    "                observation_fn=robot_observation,\n",
    "                h_states=positions,\n",
    "                v_states=colors,\n",
    "                h_name=\"position\",\n",
    "                v_name=\"color\")\n",
    "\n",
    "map_states, map_value = viterbi.map_query(robot_HMM, evidence=observed_colors)\n",
    "\n",
    "\n",
    "print(\"Traj:\", observed_colors)\n",
    "print(\"Infered traj.: \", map_states)\n",
    "print(\"Solution:      \", actual_trajectory)\n",
    "print(\"MAP value:\", map_value)\n",
    "\n",
    "def error(t1, t2):\n",
    "    error = 0\n",
    "    for c1, c2 in zip(t1, t2):\n",
    "        if c1 != c2:\n",
    "            error += 1\n",
    "    return error/len(t1)\n",
    "\n",
    "print(\"Map states:\",map_states)\n",
    "print(\"Error:\", error(map_states, actual_trajectory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI7Czszu3Jx4"
   },
   "source": [
    "### MAP queries in the typo correction setting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDix-T8w3Jx4"
   },
   "source": [
    "Correct the following word containing typos with the HMM: ['i','n','t','r','o','x','u','c','t','i','i','n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "J4fynBY63Jx4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'n', 'n', 't', 't', 't', 't', 'o', 'o', 's', 's', 'u', 'u', 'c', 'c', 't', 't', 'u', 'u', 'i', 'i', 'n', 'n']\n",
      "0.0034127995358762954\n"
     ]
    }
   ],
   "source": [
    "word = ['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
    "\n",
    "\n",
    "map_states, map_value = viterbi.map_query(word_hmm,word)\n",
    "\n",
    "print(map_states)\n",
    "print(map_value)\n",
    "\n",
    "\n",
    "#print(\"Error:\", error(map_states, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXEMSps43Jx5"
   },
   "source": [
    "Now, let's correct the full text. We have the original text and the one that contains typos in the variables original_text and typos10_text respectively. We provide a function above to test the error between two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pWyE6Kun3Jx5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected: 0.5594499865192775\n",
      "Not corrected: 0.08248604465709729\n"
     ]
    }
   ],
   "source": [
    "rec10_text = []\n",
    "for word in typos10_text.split(\" \"):\n",
    "    chs = [c for c in word]\n",
    "    \n",
    "    # ...\n",
    "    # build hmm model\n",
    "    word_hmm = HMM(n_vars=len(word),\n",
    "               prior_fn=text10_prior,\n",
    "               transition_fn=text10_transition,\n",
    "               observation_fn=text10_observation,\n",
    "               h_states=characters,\n",
    "               v_states=characters,\n",
    "               h_name=\"c\",\n",
    "               v_name=\"c_typed\")\n",
    "    \n",
    "    # run viterbi to get MAP states\n",
    "    #print(chs)\n",
    "    #print(word)\n",
    "    map_states, map_value = viterbi.map_query(word_hmm, evidence=chs)\n",
    "    \n",
    "    new_word = map_states\n",
    "    rec10_text.append(\"\".join(new_word))\n",
    "rec10_text = \" \".join(rec10_text)\n",
    "\n",
    "print(\"Corrected:\", error(rec10_text, original_text))\n",
    "print(\"Not corrected:\", error(typos10_text, original_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynytolmY3Jx5"
   },
   "source": [
    "Do the same for the case of 20% of error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dCRJiNCo3Jx5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected: 0.26446578091999823\n",
      "Not corrected: 0.16143341307814993\n"
     ]
    }
   ],
   "source": [
    "rec20_text = []\n",
    "for word in typos20_text.split(\" \"):\n",
    "    chs = [c for c in word]\n",
    "    \n",
    "    # ...\n",
    "    # build hmm model\n",
    "    word_hmm = HMM(n_vars=len(word),\n",
    "               prior_fn=text20_prior,\n",
    "               transition_fn=text20_transition,\n",
    "               observation_fn=text20_observation,\n",
    "               h_states=characters,\n",
    "               v_states=characters,\n",
    "               h_name=\"c\",\n",
    "               v_name=\"c_typed\")\n",
    "    \n",
    "    # run viterbi to get MAP states\n",
    "    #print(chs)\n",
    "    #print(word)\n",
    "    map_states, map_value = viterbi.map_query(word_hmm, evidence=chs)\n",
    "    \n",
    "    new_word = map_states\n",
    "    rec20_text.append(\"\".join(new_word))\n",
    "rec20_text = \" \".join(rec10_text)\n",
    "\n",
    "print(\"Corrected:\", error(rec20_text, original_text))\n",
    "print(\"Not corrected:\", error(typos20_text, original_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nI78Lw5y3Jx6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "version1_hmms(1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d5eff1da324760b336a6f7b5a5aadc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "074c026fa2d4461b94ebe95d2d7d62bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02d5eff1da324760b336a6f7b5a5aadc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d609507d82d64024beebaec158078844",
      "value": 0
     }
    },
    "075a54fdf0044a35b7fd840ceb248c7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "176bea0bc3d14dd587bbd31a70bbefad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dcf022d089042e3a7bb68b4a220293b",
      "placeholder": "​",
      "style": "IPY_MODEL_d2dfc0b53ccc4d52979b8a5b1fe9d3b6",
      "value": "Eliminating: position6: 100%"
     }
    },
    "33d6462d848a4bb395b061f3e3cfe0f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e88c062bf554b2f9c1cd4de74b98704": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527a4d7870a54e159d3e3d6d0007f10c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6dcf022d089042e3a7bb68b4a220293b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74a2644138a74c2999934b46eeb38a0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e45d82eaba7542f78e9d13108d5d12c5",
      "placeholder": "​",
      "style": "IPY_MODEL_87595bc31e47432081e449aeb396694a",
      "value": ""
     }
    },
    "87595bc31e47432081e449aeb396694a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99d16e6768e84c34b8042e210fab56b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e88c062bf554b2f9c1cd4de74b98704",
      "placeholder": "​",
      "style": "IPY_MODEL_527a4d7870a54e159d3e3d6d0007f10c",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "a0b3c38228d6444d8b7ef87c7adbb9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a99fcb6a400e4940992300f86f5f511f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7d451aea51d469d90e74a9dd62dd30e",
      "placeholder": "​",
      "style": "IPY_MODEL_a0b3c38228d6444d8b7ef87c7adbb9b7",
      "value": " 6/6 [00:00&lt;00:00, 67.39it/s]"
     }
    },
    "b2e500ac2cc14f87971e7b8dc5f3c707": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74a2644138a74c2999934b46eeb38a0d",
       "IPY_MODEL_074c026fa2d4461b94ebe95d2d7d62bb",
       "IPY_MODEL_99d16e6768e84c34b8042e210fab56b8"
      ],
      "layout": "IPY_MODEL_e0a5c37ad2ea4541a9141631783e1533"
     }
    },
    "c314412f3b8d433a84781822dc1179e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_075a54fdf0044a35b7fd840ceb248c7a",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33d6462d848a4bb395b061f3e3cfe0f5",
      "value": 6
     }
    },
    "c9808d6086d24640b36b8509292a28b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_176bea0bc3d14dd587bbd31a70bbefad",
       "IPY_MODEL_c314412f3b8d433a84781822dc1179e1",
       "IPY_MODEL_a99fcb6a400e4940992300f86f5f511f"
      ],
      "layout": "IPY_MODEL_ce9dfff3d6874d50ab0d409703c4b438"
     }
    },
    "ce9dfff3d6874d50ab0d409703c4b438": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2dfc0b53ccc4d52979b8a5b1fe9d3b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d609507d82d64024beebaec158078844": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0a5c37ad2ea4541a9141631783e1533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e45d82eaba7542f78e9d13108d5d12c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7d451aea51d469d90e74a9dd62dd30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
